---
title: How to Switch Between Different Models
sidebarTitle: Switching Models
---

When working with Agno, you may need to switch between different models. While Agno supports 20+ model providers, switching between different providers can cause compatibility issues. Switching models within the same provider is generally safer and more reliable.

## Recommended Approach

**Safe:** Switch models within the same provider (OpenAI → OpenAI, Google → Google)  
**Risky:** Switch between different providers (OpenAI ↔ Google ↔ Anthropic)

## Safe Model Switching

The safest way to switch models is to change the model ID while keeping the same provider:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat

# From GPT-4o to GPT-4o-mini (same provider)
expensive_agent = Agent(model=OpenAIChat(id="gpt-4o"))
budget_agent = Agent(model=OpenAIChat(id="gpt-4o-mini"))
```

## Cross-Provider Switching

Switching between providers can cause compatibility issues and is not recommended for production use without thorough testing:

```python
# OpenAI to Google Gemini
from agno.models.openai import OpenAIChat
from agno.models.google import Gemini

openai_agent = Agent(model=OpenAIChat(id="gpt-4o"))
gemini_agent = Agent(model=Gemini(id="gemini-2.0-flash-001"))
```

## Common Issues

When switching between providers, you may encounter:

- **API key differences**: Each provider requires different environment variables
- **Tool compatibility**: Tools may work differently across providers  
- **response_model conflicts**: Some providers don't support tools + response_model together
- **Model reuse problems**: Sharing model instances between agents can cause state issues
- **Feature variations**: Not all providers support all agno features
- **Role mapping differences**: Message role names vary between providers

## Setup Requirements

Each provider needs different API keys:

```bash
# OpenAI
export OPENAI_API_KEY="your-openai-key"

# Google Gemini  
export GOOGLE_API_KEY="your-google-key"

# Anthropic Claude
export ANTHROPIC_API_KEY="your-anthropic-key"
```

If you need to switch providers, test thoroughly in a development environment first.

## Troubleshooting Common Switch Issues

### Tools + response_model conflicts
Some providers (Gemini, OpenRouter) don't support tools and response_model simultaneously:

```python
# This may fail with Gemini
agent = Agent(
    model=Gemini(id="gemini-2.0-flash-001"),
    tools=[SomeTools()],
    response_model=MyModel,  # Conflict!
)

# Solution: Use separately or try use_json_mode=True
agent = Agent(
    model=Gemini(id="gemini-2.0-flash-001"),
    tools=[SomeTools()],
    response_model=MyModel,
    use_json_mode=True  # May resolve conflict
)
```

### Model reuse issues
Don't share model instances between agents with different response_models:

```python
# Problematic: model state can persist
shared_model = OpenAIChat(id="gpt-4o")
agent1 = Agent(model=shared_model, response_model=ModelA)
agent2 = Agent(model=shared_model, response_model=ModelB)  # May use ModelA

# Better: Create separate model instances
agent1 = Agent(model=OpenAIChat(id="gpt-4o"), response_model=ModelA)
agent2 = Agent(model=OpenAIChat(id="gpt-4o"), response_model=ModelB)
```

## Learn More

- [All supported models](/concepts/models/introduction)
- [Environment variables setup](/faq/environment-variables)
