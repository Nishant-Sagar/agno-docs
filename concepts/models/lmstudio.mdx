---
title: LM Studio
description: Learn how to use LM Studio with Agno.
---

Run Large Language Models locally with LM Studio

[LM Studio](https://lmstudio.ai) is a fantastic tool for running models locally.

LM Studio supports multiple open-source models. See the library [here](https://lmstudio.ai/models).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

- `llama3.3` models are good for most basic use-cases.
- `qwen` models perform specifically well with tool use.
- `deepseek-r1` models have strong reasoning capabilities.
- `phi4` models are powerful, while being really small in size.

## Set up a model

Install [LM Studio](https://lmstudio.ai), download the model you want to use, and run it.

## Example

After you have the model locally, use the `LM Studio` model class to access it

<CodeGroup>

```python agent.py
from agno.agent import Agent
from agno.models.lmstudio import LMStudio

agent = Agent(
    model=LMStudio(id="qwen2.5-7b-instruct-1m"),
    markdown=True
)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story.")
```

</CodeGroup>

<Note> View more examples [here](/examples/models/lmstudio/basic). </Note>

## Params

| Parameter    | Type               | Default                        | Description                                                           |
| ------------ | ------------------ | ------------------------------ | --------------------------------------------------------------------- |
| `id`         | `str`              | `"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF"` | The id of the LMStudio model to use       |
| `name`       | `str`              | `"LMStudio"`                   | The name of the model                                                 |
| `provider`   | `str`              | `"LMStudio"`                   | The provider of the model                                             |
| `api_key`    | `Optional[str]`    | `None`                         | The API key for LMStudio (usually not needed for local)              |
| `base_url`   | `str`              | `"http://localhost:1234/v1"`  | The base URL for the local LMStudio server                            |

`LM Studio` also supports the params of [OpenAI](/reference/models/openai).
