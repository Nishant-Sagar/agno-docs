---
title: Requesty
description: Learn how to use Requesty with Agno.
---

Requesty AI is an LLM gateway with AI governance, providing unified access to various language models with built-in governance and monitoring capabilities.

Learn more about Requesty's features at [requesty.ai](https://www.requesty.ai).

## Authentication

Set your `REQUESTY_API_KEY` environment variable. Get your key from Requesty.

<CodeGroup>

```bash Mac
export REQUESTY_API_KEY=***
```

```bash Windows
setx REQUESTY_API_KEY ***
```

</CodeGroup>

## Example

Use `Requesty` with your `Agent`:

<CodeGroup>

```python agent.py
from agno.agent import Agent
from agno.models.requesty import Requesty

agent = Agent(model=Requesty(id="openai/gpt-4o"), markdown=True)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

```

</CodeGroup>

<Note> View more examples [here](/examples/models/requesty/basic). </Note>

## Params

| Parameter    | Type               | Default                        | Description                                                           |
| ------------ | ------------------ | ------------------------------ | --------------------------------------------------------------------- |
| `id`         | `str`              | `"openai/gpt-4.1"`             | The id of the model to use through Requesty                          |
| `name`       | `str`              | `"Requesty"`                   | The name of the model                                                 |
| `provider`   | `str`              | `"Requesty"`                   | The provider of the model                                             |
| `api_key`    | `Optional[str]`    | `None`                         | The API key for Requesty (defaults to REQUESTY_API_KEY env var)      |
| `base_url`   | `str`              | `"https://router.requesty.ai/v1"` | The base URL for the Requesty API                                |
| `max_tokens` | `int`              | `1024`                         | The maximum number of tokens to generate                              |

`Requesty` also supports the params of [OpenAI](/reference/models/openai).
