---
title: Running Agents
description: Learn how to run an agent and get the response.
---

The `Agent.run()` function runs the agent and generates a response, either as a `RunOutput` object or a stream of `RunOutputEvent` objects.

<Note>
  Many of our examples use `agent.print_response()` which is a helper utility to
  print the response in the terminal. It uses `agent.run()` under the hood.
</Note>

## Running Agents

Here's how to run your agent. The response is captured in the `response`.

```python
from agno.agent import Agent, RunOutput
from agno.models.openai import OpenAIChat
from agno.utils.pprint import pprint_run_response

agent = Agent(model=OpenAIChat(id="gpt-5-mini"))

# Run agent and return the response as a variable
response: RunOutput = agent.run("Tell me a 5 second short story about a robot")

# Print the response in markdown format
pprint_run_response(response, markdown=True)
```

<Tip>
You can also run the agent asynchronously using the `Agent.arun()` method.
See the [Async Agent](/examples/concepts/agent/async/basic) example.
</Tip>

### Print Response

For development purposes, you can also print the response in the terminal using the `Agent.print_response()` method.

```python
agent.print_response("Tell me a 5 second short story about a robot")

# Or for streaming
agent.print_response("Tell me a 5 second short story about a robot", stream=True)
```

<Note>
The `Agent.print_response()` method is a helper method that uses the `Agent.run()` method under the hood. 
This is only for convenience during development and not recommended for production use.

See the [Agent class reference](/reference/agents/agent) for more details.
</Note>


For information about using structured input and output with agents, including typesafe patterns, see the [Input and Output](/concepts/agents/input-output) documentation.

### RunOutput

The `Agent.run()` function returns a `RunOutput` object when not streaming. Here are some of the core attributes:

- `run_id`: The id of the run.
- `agent_id`: The id of the agent.
- `agent_name`: The name of the agent.
- `session_id`: The id of the session.
- `user_id`: The id of the user.
- `content`: The response content.
- `content_type`: The type of content. In the case of structured output, this will be the class name of the pydantic model.
- `reasoning_content`: The reasoning content.
- `messages`: The list of messages sent to the model.
- `metrics`: The metrics of the run. For more details see [Metrics](/concepts/agents/metrics).
- `model`: The model used for the run.

See detailed documentation in the [RunOutput](/reference/agents/run-response) documentation.


## Streaming Responses

To enable streaming, set `stream=True` when calling `run()`. This will return an iterator of `RunOutputEvent` objects instead of a single response.

```python
from typing import Iterator
from agno.agent import Agent, RunOutputEvent
from agno.models.openai import OpenAIChat
from agno.utils.pprint import pprint_run_response

agent = Agent(model=OpenAIChat(id="gpt-4-mini"))

# Run agent and return the response as a stream
response_stream: Iterator[RunOutputEvent] = agent.run(
    "Tell me a 5 second short story about a lion",
    stream=True
)

# Print the response stream in markdown format
pprint_run_response(response_stream, markdown=True)
```

<Tip>
You can also run the agent asynchronously using the `Agent.arun()` method. 
See the [Async Agent Streaming](/examples/concepts/agent/async/streaming) example.
</Tip>

### Streaming Intermediate Steps

For even more detailed streaming, you can enable intermediate steps by setting `stream_intermediate_steps=True`. This will provide real-time updates about the agent's internal processes.

```python
# Stream with intermediate steps
response_stream: Iterator[RunOutputEvent] = agent.run(
    "Tell me a 5 second short story about a lion",
    stream=True,
    stream_intermediate_steps=True
)
```

### Handling Events

You can process events as they arrive by iterating over the response stream:

```python
response_stream = agent.run("Tell me a 5 second short story about a lion", stream=True, stream_intermediate_steps=True)

for event in response_stream:
    if event.event == "RunContent":
        print(f"Content: {event.content}")
    elif event.event == "ToolCallStarted":
        print(f"Tool call started: {event.tool}")
    elif event.event == "ReasoningStep":
        print(f"Reasoning step: {event.content}")
    ...
```

You can see this behavior in action in the [AgentOS UI](https://os.agno.com/chat/agents).

### Storing Events

You can store all the events that happened during a run on the `RunOutput` object.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.utils.pprint import pprint_run_response

agent = Agent(model=OpenAIChat(id="gpt-5-mini"), store_events=True)

response = agent.run("Tell me a 5 second short story about a lion", stream=True, stream_intermediate_steps=True)
pprint_run_response(response)

for event in response.events:
    print(event.event)
```

By default the `RunContentEvent` event is not stored (because it would be very verbose). You can modify which events are skipped by setting the `events_to_skip` parameter.

For example:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.run.agent import RunEvent

agent = Agent(model=OpenAIChat(id="gpt-5-mini"), store_events=True, events_to_skip=[RunEvent.run_started])
```

### Event Types

The following events are yielded by the `Agent.run()` and `Agent.arun()` functions depending on the agent's configuration:

#### Core Events

| Event Type               | Description                                                                                                    |
| ------------------------ | -------------------------------------------------------------------------------------------------------------- |
| `RunStarted`             | Indicates the start of a run                                                                                   |
| `RunContent`             | Contains the model's response text as individual chunks                                                        |
| `RunIntermediateContent` | Contains the model's intermediate response text as individual chunks. This is used when `output_model` is set. |
| `RunCompleted`           | Signals successful completion of the run                                                                       |
| `RunError`               | Indicates an error occurred during the run                                                                     |
| `RunCancelled`           | Signals that the run was cancelled                                                                             |

#### Control Flow Events

| Event Type     | Description                                  |
| -------------- | -------------------------------------------- |
| `RunPaused`    | Indicates the run has been paused            |
| `RunContinued` | Signals that a paused run has been continued |

#### Tool Events

| Event Type          | Description                                                    |
| ------------------- | -------------------------------------------------------------- |
| `ToolCallStarted`   | Indicates the start of a tool call                             |
| `ToolCallCompleted` | Signals completion of a tool call, including tool call results |

#### Reasoning Events

| Event Type           | Description                                          |
| -------------------- | ---------------------------------------------------- |
| `ReasoningStarted`   | Indicates the start of the agent's reasoning process |
| `ReasoningStep`      | Contains a single step in the reasoning process      |
| `ReasoningCompleted` | Signals completion of the reasoning process          |

#### Memory Events

| Event Type              | Description                                     |
| ----------------------- | ----------------------------------------------- |
| `MemoryUpdateStarted`   | Indicates that the agent is updating its memory |
| `MemoryUpdateCompleted` | Signals completion of a memory update           |

#### Parser Model events

| Event Type                     | Description                                      |
| ------------------------------ | ------------------------------------------------ |
| `ParserModelResponseStarted`   | Indicates the start of the parser model response |
| `ParserModelResponseCompleted` | Signals completion of the parser model response  |

#### Output Model events

| Event Type                     | Description                                      |
| ------------------------------ | ------------------------------------------------ |
| `OutputModelResponseStarted`   | Indicates the start of the output model response |
| `OutputModelResponseCompleted` | Signals completion of the output model response  |


### Custom Events

If you are using your own custom tools, it will often be useful to be able to yield custom events. Your custom events will be yielded together with the rest of the expected Agno events.

We recommend creating your custom event class extending the built-in `CustomEvent` class:


```python
from dataclasses import dataclass
from agno.run.agent import CustomEvent

@dataclass
class CustomerProfileEvent(CustomEvent):
    """CustomEvent for customer profile."""

    customer_name: Optional[str] = None
    customer_email: Optional[str] = None
    customer_phone: Optional[str] = None
```


You can then yield your custom event from your tool. The event will be handled internally as an Agno event, and you will be able to access it in the same way you would access any other Agno event.

```python
from agno.tools import tool

@tool()
async def get_customer_profile():
    """Example custom tool that simply yields a custom event."""

    yield CustomerProfileEvent(
        customer_name="John Doe",
        customer_email="john.doe@example.com",
        customer_phone="1234567890",
    )
```

See the [full example](/examples/concepts/agent/events/custom_events) for more details.

## Interactive CLI 

You can also interact with the agent via a CLI.

```python
agent.cli_app(input="Tell me a 5 second short story about a robot", stream=True)
```

See the [Agent class reference](/reference/agents/agent) for more details.

## Agno Telemetry

Agno logs which model an agent used so we can prioritize updates to the most popular providers. You can disable this by setting `AGNO_TELEMETRY=false` in your environment or by setting `telemetry=False` on the agent.

```bash
export AGNO_TELEMETRY=false
```
or:
```python
agent = Agent(model=OpenAIChat(id="gpt-5-mini"), telemetry=False)
```

See the [Agent class reference](/reference/agents/agent) for more details.

## Developer Resources

- View the [Agent reference](/reference/agents/agent)
- View the [RunOutput schema](/reference/agents/run-response)
- View [Agent Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agents/README.md)
