---
title: Ollama Cloud
---

## Code

```python cookbook/models/ollama/ollama_cloud.py
from agno.agent import Agent
from agno.models.ollama import Ollama

agent = Agent(
    model=Ollama(id="deepseek-v3.1:671b", host="https://ollama.com"),
)

agent.print_response("How many r's in the word 'strawberry'?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set up Ollama Cloud API Key">
    Sign up at [ollama.com](https://ollama.com) and get your API key, then export it:
    ```bash
    export OLLAMA_API_KEY=your_api_key_here
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
    ```bash Mac
    python cookbook/models/ollama/ollama_cloud.py
    ```

    ```bash Windows
    python cookbook/models/ollama/ollama_cloud.py
    ```
    </CodeGroup>
  </Step>
</Steps>

## Key Features

- **No local setup required**: Access powerful models instantly without downloading or managing local installations
- **Production-ready**: Enterprise-grade infrastructure with reliable uptime and performance
- **Wide model selection**: Access to popular models like DeepSeek, Qwen, Phi, and more
- **Automatic configuration**: When `api_key` is provided, the host automatically defaults to `https://ollama.com`
