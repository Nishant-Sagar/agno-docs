---
title: Audio to Text Transcription
---

This example demonstrates how to create an agent that can transcribe audio conversations, identifying different speakers and providing accurate transcriptions.

## Code

```python audio_to_text.py
import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
)

url = "https://agno-public.s3.us-east-1.amazonaws.com/demo_data/QA-01.mp3"

response = requests.get(url)
audio_content = response.content

# Give a transcript of this audio conversation. Use speaker A, speaker B to identify speakers.

agent.print_response(
    "Give a transcript of this audio conversation. Use speaker A, speaker B to identify speakers.",
    audio=[Audio(content=audio_content)],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno google-generativeai requests
    ```
  </Step>

  <Step title="Export your OpenAI API key">
    Set your `OPENAI_API_KEY` as an environment variable. For most examples this is sufficient; some examples may require additional provider keys.

    <CodeGroup>

    ```bash Mac/Linux
      export OPENAI_API_KEY="your_openai_api_key_here"
    ```

    ```bash Windows
      $Env:OPENAI_API_KEY="your_openai_api_key_here"
    ```
    </CodeGroup> 
  </Step>

  <Step title="Create a Python file">
    Create a Python file and add the above code.
    ```bash
    touch audio_to_text.py
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
    ```bash Mac
    python audio_to_text.py
    ```
    
    ```bash Windows
    python audio_to_text.py
    ```
    </CodeGroup>
  </Step>

  <Step title="Find All Cookbooks">
  Explore all the available cookbooks in the Agno repository. Click the link below to view the code on GitHub:

  <Link href="https://github.com/agno-agi/agno/tree/main/cookbook" target="_blank">
    Agno Cookbooks on GitHub
  </Link>
</Step>
</Steps>