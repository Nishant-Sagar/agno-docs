---
title: Langfuse Via Openinference Response Model
---

## Code

```python cookbook/integrations/observability/langfuse_via_openinference_response_model.py
import base64
import os
from enum import Enum

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from openinference.instrumentation.agno import AgnoInstrumentor
from opentelemetry import trace as trace_api
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor
from pydantic import BaseModel, Field

LANGFUSE_AUTH = base64.b64encode(
    f"{os.getenv('LANGFUSE_PUBLIC_KEY')}:{os.getenv('LANGFUSE_SECRET_KEY')}".encode()
).decode()
os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = (
    "https://us.cloud.langfuse.com/api/public/otel"  # 🇺🇸 US data region
)
# os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"]="https://cloud.langfuse.com/api/public/otel" # 🇪🇺 EU data region
# os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"]="http://localhost:3000/api/public/otel" # 🏠 Local deployment (>= v3.22.0)

os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = f"Authorization=Basic {LANGFUSE_AUTH}"


tracer_provider = TracerProvider()
tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))
trace_api.set_tracer_provider(tracer_provider=tracer_provider)

# Start instrumenting agno
AgnoInstrumentor().instrument()


class ContentType(Enum):
    NEWS = "news"
    ARTICLE = "article"
    BLOG = "blog"
    RESEARCH = "research"
    OTHER = "other"


class WebSearchResult(BaseModel):
    title: str = Field(description="The title of the search result")
    url: str = Field(description="The URL of the search result")
    snippet: str = Field(description="A brief description or snippet from the result")
    content_type: ContentType = Field(description="The type of content found")
    relevance_score: int = Field(description="Relevance score from 1-10", ge=1, le=10)


agent = Agent(
    name="Web Research Agent",
    model=OpenAIChat(id="gpt-4o-mini"),
    tools=[DuckDuckGoTools()],
    instructions="You are a web research agent. Use DuckDuckGo to search the web and find relevant information. Analyze the search results and provide structured information about what you find.",
    debug_mode=True,
    output_schema=WebSearchResult,
)

agent.print_response("What are the latest developments in artificial intelligence?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
  Either self-host or sign up for an account at https://us.cloud.langfuse.com
    ```bash
    export LANGFUSE_PUBLIC_KEY=<your-key>
    export LANGFUSE_SECRET_KEY=<your-key>
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno ddgs langfuse opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
    ```bash Mac
    python cookbook/integrations/observability/langfuse_via_openinference_response_model.py
    ```

    ```bash Windows
    python cookbook/integrations/observability/langfuse_via_openinference_response_model.py
    ```
    </CodeGroup>
  </Step>
</Steps>