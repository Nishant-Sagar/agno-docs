---
title: CSV Row Chunking
---

CSV row chunking is a method of splitting documents into smaller chunks by using a model to determine natural breakpoints in the text. Rather than splitting text at fixed character counts, it analyzes the content to find semantically meaningful boundaries like paragraph breaks and topic transitions.

## Code

```python   
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.row import RowChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.csv_reader import CSVReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = Knowledge(
    vector_db=PgVector(table_name="imdb_movies_row_chunking", db_url=db_url),
)

asyncio.run(knowledge_base.add_content(
    url="https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
    reader=CSVReader(
        chunking_strategy=RowChunking(),
    ),
))  

# Initialize the Agent with the knowledge_base
agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)

# Use the agent 
agent.print_response("Tell me about the movie Guardians of the Galaxy", markdown=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector agno
    ```
  </Step>


    <Snippet file="run-pgvector-step.mdx" />


  <Step title="Run Agent">
    <CodeGroup>
    ```bash Mac
    python cookbook/knowledge/chunking/csv_row_chunking.py
    ```

    ```bash Windows
    python cookbook/knowledge/chunking/csv_row_chunking.py 
    ```
    </CodeGroup>
  </Step>
</Steps>

## CSV Row Chunking Params

<Snippet file="chunking-csv-row.mdx" /> 
